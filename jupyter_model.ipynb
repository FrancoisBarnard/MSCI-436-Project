{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note:\n",
    "The algorithm and a large part of the model implementation is based off of Kaggle user \"Niharika Pandit\"'s notebook at\n",
    "https://www.kaggle.com/code/niharika41298/netflix-visualizations-recommendation-eda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import streamlit as st\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "netflix = pd.read_csv(\"data/netflix_titles.csv\")\n",
    "amazon = pd.read_csv(\"data/amazon_prime_titles.csv\")\n",
    "hulu = pd.read_csv(\"data/hulu_titles.csv\")\n",
    "disney = pd.read_csv(\"data/disney_plus_titles.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining the initial data without any labels for origin\n",
    "data = pd.concat([netflix, amazon, hulu, disney], ignore_index=True)\n",
    "\n",
    "# Removing \"na\" fields\n",
    "data = data.fillna(\"\")\n",
    "\n",
    "# Removing any duplicate movies\n",
    "data = data.drop_duplicates(subset=[\"title\", \"type\"], keep=\"last\")\n",
    "\n",
    "# Adding a label to all the data with their source\n",
    "netflix = netflix.assign(netflix=1, amazon=0, hulu=0, disney=0)\n",
    "amazon = amazon.assign(netflix=0, amazon=1, hulu=0, disney=0)\n",
    "hulu = hulu.assign(netflix=0, amazon=0, hulu=1, disney=0)\n",
    "disney = disney.assign(netflix=0, amazon=0, hulu=0, disney=1)\n",
    "\n",
    "# Defining aggregate functions\n",
    "g = {\"netflix\": \"sum\", \"amazon\": \"sum\", \"hulu\": \"sum\", \"disney\": \"sum\"}\n",
    "\n",
    "# Creating a temporary dataframe with only titles, type, & origins\n",
    "data_temp = pd.concat([netflix, amazon, hulu, disney], ignore_index=True).groupby(\n",
    "    [\"title\", \"type\"], as_index=False).agg(g).reset_index()\n",
    "data_temp = data_temp.fillna(\"\")\n",
    "\n",
    "# Merging the two dataframes together to create a complete system\n",
    "# Inner merge information found via TutorialsPoint tutorial\n",
    "# Source: https://www.tutorialspoint.com/python_pandas/python_pandas_merging_joining.htm\n",
    "data = pd.merge(data, data_temp, on=[\"title\", \"type\"], how=\"inner\")\n",
    "\n",
    "untouched_data = data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(data):\n",
    "    \"\"\"\n",
    "    Define a function to \"clean\" the data by forcing all needed groups lowercase\n",
    "    \"\"\"\n",
    "    return str.lower(data.replace(\" \", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fbarn\\AppData\\Local\\Temp/ipykernel_184692/3012349721.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[feature] = data[feature].apply(clean_data)\n"
     ]
    }
   ],
   "source": [
    "# Identifying features for the model\n",
    "features = [\"title\", \"director\", \"cast\", \"listed_in\", \"description\"]\n",
    "data = data[features]\n",
    "\n",
    "# Apply cleaning function\n",
    "for feature in features:\n",
    "    data[feature] = data[feature].apply(clean_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_soup(data):\n",
    "    \"\"\"\n",
    "    Create a \"soup\" or \"bag of words\" for all rows\n",
    "    \"\"\"\n",
    "    return data[\"title\"] + \" \" + data[\"director\"] + \" \" + data[\"cast\"] + \" \" + data[\"listed_in\"] + \" \" + data[\"description\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fbarn\\AppData\\Local\\Temp/ipykernel_184692/2938150909.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[\"soup\"] = data.apply(create_soup, axis=1)\n"
     ]
    }
   ],
   "source": [
    "data[\"soup\"] = data.apply(create_soup, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22242, 22242)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = CountVectorizer(stop_words=\"english\")\n",
    "count_matrix = count.fit_transform(data[\"soup\"])\n",
    "\n",
    "cosine_sim = cosine_similarity(count_matrix, count_matrix)\n",
    "cosine_sim.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.reset_index()\n",
    "indices = pd.Series(data.index, index=data[\"title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations(title, cosine_sim=cosine_sim):\n",
    "    \"\"\"\n",
    "    Get recommendations based off of input movie title\n",
    "    \"\"\"\n",
    "    title = title.replace(' ', '').lower()\n",
    "    idx = indices[title]\n",
    "\n",
    "    # Get the pairwsie similarity scores of all movies with that movie\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "\n",
    "    # Sort the movies based on the similarity scores\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Get the scores of the 10 most similar movies\n",
    "    sim_scores = sim_scores[1:11]\n",
    "\n",
    "    # Get the movie indices\n",
    "    movie_indices = [i[0] for i in sim_scores]\n",
    "\n",
    "    # Return the top 10 most similar movies\n",
    "    return untouched_data['title'].iloc[movie_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_service(recommendation):\n",
    "    \"\"\"\n",
    "    Returns the count of where the recommendations can be found\n",
    "    \"\"\"\n",
    "    output = {\n",
    "        \"netflix\": 0,\n",
    "        \"amazon\": 0,\n",
    "        \"hulu\": 0,\n",
    "        \"disney\": 0\n",
    "    }\n",
    "    print(recommendation)\n",
    "    for title in recommendation:\n",
    "        output[\"netflix\"] += int(untouched_data.loc[untouched_data[\"title\"]\n",
    "                                 == title, \"netflix\"].values[0])\n",
    "        output[\"amazon\"] += int(untouched_data.loc[untouched_data[\"title\"]\n",
    "                                == title, \"amazon\"].values[0])\n",
    "        output[\"hulu\"] += int(untouched_data.loc[untouched_data[\"title\"]\n",
    "                              == title, \"hulu\"].values[0])\n",
    "        output[\"disney\"] += int(untouched_data.loc[untouched_data[\"title\"]\n",
    "                                == title, \"disney\"].values[0])\n",
    "\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20536                                     Naruto Shippuden\n",
      "20706                                              Sonic X\n",
      "20672                                            One Piece\n",
      "18814                                           Fire Force\n",
      "19400                                     Digimon Frontier\n",
      "20363                                             Basilisk\n",
      "20778                                             Primeval\n",
      "19669       Pokémon the Movie: Hoopa and the Clash of Ages\n",
      "19670    Pokémon The Movie: Volcanion and the Mechanica...\n",
      "19978                               Voltron: Fleet Of Doom\n",
      "Name: title, dtype: object\n",
      "{'netflix': 1, 'amazon': 1, 'hulu': 10, 'disney': 0}\n"
     ]
    }
   ],
   "source": [
    "recommendations = get_recommendations(\"naruto\", cosine_sim)\n",
    "\n",
    "final = get_best_service(recommendations)\n",
    "print(final)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "63aba52e814add56b12814e8e9687bd3b74d518fb295e1ddf508212494391977"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
